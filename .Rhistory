blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
```r
---
title: "Hello R Markdown"
knitr::opts_chunk$set(collapse = TRUE)
summary(cars)
fit <- lm(dist ~ speed, data = cars)
fit
par(mar = c(0, 1, 0, 1))
pie(
c(280, 60, 20),
c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),
col = c('#0292D8', '#F7EA39', '#C4B632'),
init.angle = -50, border = NA
)
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::new_post()
blogdown::new_post('sample test project')
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::new_post(options(blogdown.ext = '.Rmd'))
library(tidyverse)
horror_movies <- read_csv("C:/Users/samir/Documents/DATA/horror_movies.csv")
languages <- read.csv("C:/Users/samir/Documents/DATA/list_of_iso_codes-934j.csv")
languages <- languages %>%
select(Language.name, X639.1) %>%
rename(original_language = X639.1)
horror_movies %>% glimpse()
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, -median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, -median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, -median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
library(tidyverse)
horror_movies <- read_csv("C:/Users/samir/Documents/DATA/horror_movies.csv")
languages <- read.csv("C:/Users/samir/Documents/DATA/list_of_iso_codes-934j.csv")
languages <- languages %>%
select(Language.name, X639.1) %>%
rename(original_language = X639.1)
horror_movies %>% glimpse()
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, -median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
![]['/Samir Website/content/post/2023-03-07-md/plot 1.png']
![]['/Samir Website/content/post/2023-03-07-md/plot 1.png']
!['/Samir Website/content/post/2023-03-07-md/plot 1.png']
!['/Samir Website/content/post/2023-03-07-md/plot 1.png']
!('/Samir Website/content/post/2023-03-07-md/plot 1.png')
blogdown::serve_site()
!(/Samir Website/content/post/2023-03-07-md/plot 1.png)
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
plot1 <- horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
plot1
plot1
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(Language.name, median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
horror_movies_runtime <- horror_movies %>%
mutate(original_language = str_replace_all(original_language, 'cn', 'zh')) %>%
filter(runtime != is.na(runtime)) %>%
select(original_language, runtime) %>%
group_by(original_language)%>%
summarise(median_runtime = median(runtime), number_movies = n()) %>%
arrange(desc(number_movies)) %>%
head(n=25)
horror_movies_runtime %>%
left_join(languages, by = 'original_language') %>%
ggplot(aes(reorder(Language.name, -median_runtime), median_runtime))+
geom_col() +
geom_text(aes(label = median_runtime, vjust = -0.5)) +
xlab('Language') +
ylab('Median Minutes of Movie')
blogdown::serve_site()
library(tidyverse)
blogdown::shortcode("figure", src='images/language chart.png')
blogdown::shortcode("figure", src='static/images/language chart.png')
blogdown::serve_site()
rmarkdown::clean_site(preview = FALSE)
blogdown:::preview_site()
blogdown::build_site()
blogdown::serve_site()
<img src="{{< blogdown/postref >}}index_files/figure-html/pressure-1.png" width="1920" />
knitr::opts_chunk$set(collapse = TRUE)
summary(cars)
fit <- lm(dist ~ speed, data = cars)
fit
par(mar = c(0, 1, 0, 1))
pie(
c(280, 60, 20),
c('Sky', 'Sunny side of pyramid', 'Shady side of pyramid'),
col = c('#0292D8', '#F7EA39', '#C4B632'),
init.angle = -50, border = NA
)
blogdown:::preview_site()
blogdown::bundle_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
blogdown::serve_site()
rmarkdown::clean_site(preview = FALSE)
blogdown::new_post(ext = '.Rmd')
blogdown::new_post(title = 'Test Blog', ext = '.Rmd')
data("cars")
data("mtcars")
head("mtcars")
head("cars")
head(cars)
head(mtcars)
blogdown:::preview_site()
libary(tidyverse)
library(tidyverse)
install.packages(tidyverse)
library(tidyverse)
library(tidyverse)
library(tidyverse)
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()
library(tidyverse)
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()
library(dplyr)
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()+
geom_smooth()
blogdown::serve_site()
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()+
geom_smooth()
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()+
geom_smooth()
mtcars %>%
ggplot(aes(x=wt, y=hp))+
geom_point()+
geom_smooth()
blogdown::serve_site()
blogdown::serve_site()
ggplot(aes(x=mtcars$wt, y=mtcars$hp))+
geom_point()+
geom_smooth()
mtcars |>
ggplot(aes(x=wt, y=hp))+
geom_point()+
geom_smooth()
blogdown::serve_site()
blogdown::serve_site()
blogdown::build_site()
blogdown::serve_site()
library(ggplot2)
blogdown::serve_site()
rmarkdown::clean_site()
rmarkdown::clean_site(preview = FALSE)
blogdown::serve_site()
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(leaflet)
install.packages("leaflet")
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(leaflet)
library(broom)
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(leaflet)
library(broom)
breweries_list <- 1:84 %>% map(function(page) {
url <- paste0("https://api.openbrewerydb.org/breweries?by_type=micro",
"&per_page=50&page=",
page)
url %>%
fromJSON()%>%
filter(!is.na(latitude), !is.na(longitude))
})
breweries_data <- as.data.frame(do.call(rbind, breweries_list))
breweries_data <- breweries_data %>%
mutate(latitude = as.numeric(latitude),
longitude = as.numeric(longitude))
breweries_data_30 <- breweries_data %>% head(n=30) %>%
select(name, latitude, longitude)
map <- leaflet(breweries_data) %>%
addTiles() %>%
addMarkers(~breweries_data$longitude, ~breweries_data$latitude,
popup = breweries_data$name,
clusterOptions = markerClusterOptions())
map
blogdown:::preview_site()
blogdown::new_post(ext = '.rmd')
blogdown::new_post(ext = '.rmd', title = 'Twitter wordcloud')
library(tidyverse)
library(rvest)
library(httr)
library(jsonlite)
library(leaflet)
library(broom)
breweries_list <- 1:84 %>% map(function(page) {
url <- paste0("https://api.openbrewerydb.org/breweries?by_type=micro",
"&per_page=50&page=",
page)
url %>%
fromJSON()%>%
filter(!is.na(latitude), !is.na(longitude))
})
breweries_data <- as.data.frame(do.call(rbind, breweries_list))
breweries_data <- breweries_data %>%
mutate(latitude = as.numeric(latitude),
longitude = as.numeric(longitude))
breweries_data_30 <- breweries_data %>% head(n=30) %>%
select(name, latitude, longitude)
map <- leaflet(breweries_data) %>%
addTiles() %>%
addMarkers(~breweries_data$longitude, ~breweries_data$latitude,
popup = breweries_data$name,
clusterOptions = markerClusterOptions())
map
library(tidyverse)
library(jsonlite)
library(rtweet)
library(tidytext)
raw_Tweets <- read_file(file = here::here("tweet.js"))
raw_Tweets <- read_file(file = here::here("tweet.js"))
json <- sub("window.YTD.tweet.part0 = ", "", raw_Tweets)
raw_Tweets <- fromJSON(json)
raw_Tweets <- raw_Tweets$tweet
raw_Tweets <- read_file(file = here::here("tweet.js"))
json <- sub("window.YTD.tweet.part0 = ", "", raw_Tweets)
raw_Tweets <- fromJSON(json)
raw_Tweets <- raw_Tweets$tweet
clean_Tweets <- raw_Tweets %>%
filter(retweeted == FALSE) %>%
filter(!str_detect(full_text, "^RT "),
!str_detect(full_text, "^https")) %>%
mutate(retweet_count = as.integer(retweet_count),
full_text = str_replace_all(full_text, "https://t.co/[a-zA-Z0-9]*", ""),
full_text = str_replace_all(full_text, "@[a-zA-Z0-9_]*", ""))
clean_Tweets %>%
select(retweet_count, full_text) %>%
arrange(desc(retweet_count)) %>%
head(n = 5)
clean_Tweets %>%
mutate(`tweet source` = str_extract(source, "Twitter [A-Za-z ]*")) %>%
filter(!is.na(`tweet source`))  %>%
ggplot() +
geom_bar(aes(`tweet source`))
tweets <- clean_Tweets %>%
select(full_text) %>%
unnest_tokens(words, full_text)
tweets <- tweets %>%
mutate(words = str_replace_all(words, "’", "'")) %>%
anti_join(stop_words, by = c("words" = "word")) %>%
filter(!str_detect(words, "^[0-9]+")) %>%
count(words) %>%
arrange(desc(n))
tweets %>% head(n=10)
install.packages(c("wordcloud", "wordcloud2"))
library(tidyverse)
library(jsonlite)
library(rtweet)
library(tidytext)
clean_Tweets %>%
select(retweet_count, full_text) %>%
arrange(desc(retweet_count)) %>%
head(n = 5)
tweets <- clean_Tweets %>%
select(full_text) %>%
unnest_tokens(words, full_text)
tweets <- tweets %>%
mutate(words = str_replace_all(words, "’", "'")) %>%
anti_join(stop_words, by = c("words" = "word")) %>%
filter(!str_detect(words, "^[0-9]+")) %>%
count(words) %>%
arrange(desc(n))
tweets %>% head(n=10)
blogdown::serve_site()
clean_Tweets %>%
select(retweet_count, full_text) %>%
arrange(desc(retweet_count)) %>%
head(n = 5)
clean_Tweets %>%
mutate(`tweet source` = str_extract(source, "Twitter [A-Za-z ]*")) %>%
filter(!is.na(`tweet source`))  %>%
ggplot() +
geom_bar(aes(`tweet source`))
blogdown::serve_site()
library(wordcloud)
library(wordcloud2)
twitter_wordcloud <- wordcloud(words = tweets$words,
freq = tweets$n,
min.freq = 5,
random.color = TRUE)
twitter_wordcloud2 <- wordcloud2(data = tweets)
twitter_wordcloud2
